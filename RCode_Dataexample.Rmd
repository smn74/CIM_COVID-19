---
title: "R-code for reanalysis of the COVID-19 study"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This file provides the code of the analysis described in Section 3.5 of Friedrich & Friede (2020). The data set is taken from Gautret et al. (2020), https://doi.org/10.1016/j.ijantimicag.2020.105949, Supplementary Table 1.

## Data preparation

Following Gautret et al. (2020), we imput missing outcomes on Day 6 by a last-
observation-carried-forward-approach, i. e. patients with missing PCR are considered positive on Day 6, if they were actually positive the day(s) before.

```{r}
library(Publish)
library(data.table)
library(survival)
library(ggplot2)
library(zoo)
library(logistf)
# Data preparation
covid <- readRDS("covid.rds")

# Impute missing outcomes on Day 6
covid[, 8:14] <- t(na.locf(t(covid[, 8:14])))
covid <- as.data.table(covid)
# drop unused variables
covid[, c("D0", "D1", "D2", "D3", "D4", "D5", "azi") := NULL]
## re-label outcome variable
covid[, D6 := ifelse(D6 == "NEG", 1, 0)]
setnames(covid, "D6", "outcome")
covid[, hydro := ifelse(hydro == "no", 0, 1)]
setnames(covid, "hydro", "trt")
```

After setting time since onset of symptoms to zero for asymptomatic patients, two patients with
missing time since onset remain. Both patients are classified as URTI and we use the median time since onset (3 days) for URTI-patients to impute these missing values.

```{r}
# timeonset is zero for asymptomatic patients
covid[clinicalstatus == "Asymptomatic", timeonset := 0]
covid[is.na(timeonset)]
# two missing values remain (both URTI), impute using median in the respective group
replace <- covid[, median(timeonset[clinicalstatus=="URTI"], na.rm =T)]
covid[is.na(timeonset), timeonset := replace]
```

## The PS-model

Our PS-model includes sex, age, clinical status and time since onset of symptoms as explanatory variables.

```{r}
# propensity score model
propmod <- glm(trt ~ sex + age + clinicalstatus + timeonset,
               family="binomial", data = covid)
# propensity score
covid[, ps := predict(propmod, type = "response")]
```

### Compare propensity score overlap between the two groups

```{r}
data <- data.frame(treatment = covid$trt, score = covid$ps)

d1 <- density(data$score[data$treatment == 1], from = 0, to = 1, n = 200)
d0 <- density(data$score[data$treatment == 0], from = 0, to = 1, n = 200)
d <- data.frame(x = c(d1$x, d0$x), y = c(d1$y, d0$y), treatment = c(rep("Hydroxychloroquine", length(d1$x)),
                                                                    rep("Control", length(d0$x))))
d$treatment <- factor(d$treatment, levels = c("Hydroxychloroquine", "Control"))
ggplot(d, aes(x = .data$x, y = .data$y)) +
  geom_density(stat = "identity", aes(color = .data$treatment, group = .data$treatment, fill = .data$treatment)) +
  scale_fill_manual(values = c(rgb(0.8, 0, 0, alpha = 0.5),
                                        rgb(0, 0, 0.8, alpha = 0.5))) +
  scale_color_manual(values = c(rgb(0.8, 0, 0, alpha = 0.5),
                                         rgb(0, 0, 0.8, alpha = 0.5))) +
  scale_x_continuous("Propensity score", limits = c(0, 1)) +
  scale_y_continuous("Density", limits = c(0, max(d$y))) +
  theme(axis.text = element_text(size=20), axis.title = element_text(size = 20))+
  theme(legend.title = element_blank(),
                 legend.position = "top",
                 legend.text = element_text(margin = margin(0, 0.5, 0, 0.1, "cm"), size = 20))+ 
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"))

```


### IPTW analysis

```{r}
# calculate IPTW 
covid[trt == 1, w:= 1/ps]
covid[trt == 0, w:= 1/(1-ps)]

# simple model using weighted data with sandwich estimators
fit.iptw <- glm(outcome ~ trt, data = covid, weights = w, family = binomial)
library(sandwich)
library(lmtest)
tt <- coeftest(fit.iptw, vcov = sandwich)
```

### Doubly robust g-computation

The Q-model for the g-computation additionally includes treatment status and the covariate z, which is equal to the IPT weight for the treatment group and equal to the negative IPT weight in the control group.

```{r}
# simple doubly robust model
covid[trt == 0, z:= -w]
covid[trt == 1, z:= w]
 
## calculate confidence intervals using bootstrap
###
# function to calculate causal odds ratio including bootstrapped confidence intervals
library(parallel)
bootstrap <- function(data, form, iter = 10000, seed = 123, ...){
  
  # function to predict counterfactual outcomes for each hospital using g-formula
  risks <- function(data, form, ...){
    # fit Q-model for Y~A + L
    fit <- glm(form,
               data, family = binomial)
    
    predictions <- list()
    pot.outcome <- c(1, 0)
    for(i in 1:2){
      nd <- copy(data)
      nd[, outcome:=NA]
      nd[, trt := pot.outcome[i]]
      predictions[[i]] <- predict(fit, newdata = nd, type = "response")
    
    }  
    names(predictions) <- pot.outcome
    effects <- sapply(FUN = mean, predictions)
    
    return(effects)
  }
  
  risks.original <- risks(data, form)
  
  # bootstrapping
  boot <- mclapply(X=1:iter, FUN=function(i, ...){
    bindex <- sample(1:NROW(data), size = NROW(data), replace = TRUE)
    bsample <- data[bindex]
    b.risks <- risks(bsample, form)
    return(b.risks)
  })
  
 output <- list(risks=risks.original, boot = boot)
  return(output)
}

causal.or <- function(risks, boot,  ...){
  
  Y_0 <- risks["0"]
  Y_1 <- risks["1"]
  
  causal.or <- (Y_1/(1-Y_1))/(Y_0/(1-Y_0))
  
  Y_0_b <- sapply(boot, function(x){x["0"]})  
  Y_1_b <- sapply(boot, function(x){x["1"]})
  
  causal.or.b <- (Y_1_b/(1-Y_1_b))/(Y_0_b/(1-Y_0_b))
  
  q2.5 <- quantile(causal.or.b, prob = 0.025)
  q97.5 <- quantile(causal.or.b, prob = 0.975)
  
  COR <- c(q2.5, causal.or, q97.5)
  names(COR) <- c("Lower", "Estimate", "Upper")
  return(COR)
}

boots <- bootstrap(covid, form = outcome ~  trt + z + sex + age + clinicalstatus + timeonset)
CIboot <- causal.or(boots$risks, boots$boot)
```

Another possibility for a doubly robust estimator, which performed better according to Kang & Schafer (2007) is based on dummy variables according to the quintiles of the logit of the PS.

```{r}
# the same with dummy categories for logit(ps)-quintiles
qt <- quantile(log(covid$ps/(1-covid$ps)), probs = seq(0, 1, 1/5))
covid[, logitps := log(ps/(1-ps))]
 
# create dummy variables
covid[, z1:= as.numeric(logitps < qt[2])]
covid[, z2:= as.numeric(qt[2] < logitps & logitps < qt[3])]
covid[, z3:= as.numeric(qt[3] < logitps & logitps < qt[4])]
covid[, z4:= as.numeric(qt[4] < logitps & logitps < qt[5])]

boots2 <- bootstrap(covid, form = outcome ~  trt + z1 + z2 + z3 + z4 + sex + age + clinicalstatus + timeonset)
CIboot2 <- causal.or(boots2$risks, boots2$boot)
```


### Matching

The matching procedure results in a data set with 11 controls and 11 treated
patients, thus discarding 5 controls and 9 treated patients from the analysis. 

```{r}
## Matching
library(MatchIt)
ps.mod <- matchit(trt ~ sex + age + clinicalstatus + timeonset, data = covid,
                  method = "nearest", replace = FALSE, caliper = 0.2)
m.data <- match.data(ps.mod, distance = "pscore")
```

Due to the small remaining sample size, the conditional logistic regression model does not converge at all, while the
GEE procedure does not produce estimates of the standard errors and the simple model (match
unadjusted) returned confidence intervals ranging from 0 to $\infty$. Thus, the matching procedure
doesn't yield useful estimates and is discarded from the results displayed below. 

#### Unconditional analysis

```{r}
# fit regression model on matched data (unconditional)
fit.match <- logistf(outcome ~ trt, data = m.data, family = binomial)
```

#### Conditional logistic regression

```{r}
# adjusting for matched pairs
m.data$id <- rownames(m.data)
m.data <- as.data.table(m.data)
rn <- ps.mod$match.matrix[!is.na(ps.mod$match.matrix),]
m.data[id %in% names(rn), matched.id := rn]
m.data[is.na(matched.id), class:= id]
m.data[!is.na(matched.id), class:= matched.id]
# conditional logistic regression
fit.match2 <- clogit(outcome ~ trt + strata(class), data = m.data)
```

#### GEE

```{r}
# GEE
library(geepack)
# data needs to be ordered
m.data <- m.data[order(class), ]
gee.matched <- geeglm(formula   = outcome ~ trt,
                       family    = binomial(link = "logit"),
                         id        = class,
                         data      = m.data,
                         corstr    = "exchangeable",
                         scale.fix = FALSE)
summary(gee.matched)
```

### Fitting the models and putting all results in a table

```{r}
# crude OR
fit.unadj <- glm(outcome ~ trt, data = covid, family = binomial)
tab.unadj <- regressionTable(fit.unadj)$trt[c("OddsRatio", "Lower", "Upper")]

# covariate adjustment using Firth correction
fit.adj <- logistf(outcome ~ trt + sex + age + clinicalstatus + timeonset, data = covid)
tab.adj <- data.frame(OddsRatio = exp(fit.adj$coefficients[2]), Lower = exp(confint(fit.adj)[2, 1]), Upper = exp(confint(fit.adj)[2, 2]))

# PS-covariate adjustment
fit.c <- glm(outcome ~ trt + ps, data = covid, family = binomial)
tab <- regressionTable(fit.c)
tab.c <- tab$trt[c("OddsRatio", "Lower", "Upper")]

# results from the doubly robust g-estimation
tab.g.double <- data.frame(OddsRatio = CIboot["Estimate"], Lower = CIboot["Lower"], Upper = CIboot["Upper"])

tab.g.double2 <- data.frame(OddsRatio = CIboot2["Estimate"], Lower = CIboot2["Lower"], Upper = CIboot2["Upper"])

# results from matching
tab.match <- data.frame(OddsRatio = exp(fit.match$coefficients[2]), Lower = exp(confint(fit.match)[2, 1]), Upper = exp(confint(fit.match)[2, 2]))

# results from the IPTW analysis
tab.iptw <- data.frame(OddsRatio = exp(tt[2, 1]), Lower = exp(confint(tt))[2, 1], Upper = exp(confint(tt))[2, 2])

table <- rbind(tab.unadj, tab.adj, tab.c, tab.iptw, tab.g.double, tab.g.double2, tab.match)
table$method <- c("Crude OR", "Covariate adjusted (Firth)", "PS covariate", "IPTW", "Simple DR g-computation", "DR using quintiles", "Matching (Firth)")
knitr::kable(table)
```


```{r}
theme_set(theme_bw())
p1 <- ggplot(table,aes(OddsRatio,method)) + 
  geom_point(size=5, shape=18) +
  geom_errorbarh(aes(xmax = Upper, xmin = Lower), height = 0.15, lwd=1) +
  geom_vline(xintercept = 1, linetype = "longdash") +
  scale_x_log10()+
  theme(axis.text = element_text(size=14), axis.title = element_text(size = 14))+
  labs(x="Odds Ratio", y="Method")
p1
```

```{r,include=FALSE}
pdf(file = "Figures/Plot_OR_dataex.pdf")
p1
dev.off()
```

As we can see in the figure, all four methods (the crude unadjusted as well as the three
causal inference methods) yield similar point estimates, which are, however, extremely large.
Moreover, the methods differ with respect to statistical significance: The very wide confidence
interval obtained by the doubly robust g-computation approach includes 1. 

## Risk Difference

### IPTW analysis

```{r}
## risk difference
# survey package:
library(survey)
msm <- svyglm(outcome ~ trt, design = svydesign(~1, weights = ~w, data = covid))
ci.iptw <- c(confint(msm)[1, 2], coef(msm)[2], confint(msm)[2, 2])
names(ci.iptw) <- c("Lower", "Estimate", "Upper")
```

### Doubly robust g-computation

The Q-model for the g-computation additionally includes treatment status and the covariate z, which is equal to the IPT weight for the treatment group and equal to the negative IPT weight in the control group.

```{r}
# function for calculating risk difference instead of OR
causal.rd <- function(risks, boot, ...){
  
  Y_0 <- risks["0"]
  Y_1 <- risks["1"]
  
  causal.rd <- Y_1 -Y_0
  
  Y_0_b <- sapply(boot, function(x){x["0"]})  
  Y_1_b <- sapply(boot, function(x){x["1"]})
  
  causal.rd.b <- Y_1_b-Y_0_b
  
  q2.5 <- quantile(causal.rd.b, prob = 0.025)
  q97.5 <- quantile(causal.rd.b, prob = 0.975)
  
  CRD <- c(q2.5, causal.rd, q97.5)
  names(CRD) <- c("Lower", "Estimate", "Upper")
  return(CRD)
}
CIboot.rd <- causal.rd(boots$risks, boots$boot)
```

For the second DR estimator, we instead include dummy variables corresponding to the quintiles of the logit of the PS in the Q-model: 

```{r}
## calculate confidence intervals using bootstrap
CIboot.rd2 <- causal.rd(boots2$risks, boots2$boot)
```

### Matching

```{r}
## Matching
# b: only treated experience the event
b <- m.data[trt ==1 & outcome == 1, .N]
# c: only untreated experience the event
c <- m.data[trt ==0 & outcome == 1, .N]
# n: number of matched pairs
n <- (NROW(m.data)/2)

diff.match <- (b-c)/n
var <- ((b+c)-(c-b)^2/n)/n
ci.match <- c(diff.match - 1.96*var, diff.match, diff.match + 1.96*var)
```

### Fitting the models and putting all results in a table

```{r}
# PS-covariate adjustment: binomial model with identity link does not converge
glm.adj <- try(glm(outcome ~ trt + age + sex + clinicalstatus + timeonset, data = covid, family = binomial(link = "identity")))
# using linear model instead
lm.adj <- lm(outcome ~ trt + age + sex + clinicalstatus + timeonset, data = covid)
ci.adj <- c(confint(lm.adj)[2, 1], lm.adj$coefficients[2], confint(lm.adj)[2, 2])
names(ci.adj) <- c("Lower", "Estimate", "Upper")

## covariate adjustment using PS: no valid set of coefficients found
glm.cov <- try(glm(outcome ~ trt + ps, data = covid, family = binomial(link = "identity")))
# using linear model instead
lm.PScov <- lm(outcome ~ trt + ps, data = covid)
ci.PScov <- c(confint(lm.PScov)[2, 1], lm.PScov$coefficients[2], confint(lm.PScov)[2, 2])
names(ci.PScov) <- c("Lower", "Estimate", "Upper")
```

```{r}
# crude (unadjusted) risk difference
ex <- covid[trt == 1, .N]
unex <- covid[trt == 0, .N]
ex.event <- covid[trt == 1 & outcome == 1, .N]
unex.event <- covid[trt == 0 & outcome == 1, .N]

library(fmsb)
rd <- riskdifference(ex.event, unex.event, ex, unex)
ci.unadjusted <- c(rd$conf.int[1], rd$estimate, rd$conf.int[2])
names(ci.unadjusted) <- c("Lower", "Estimate", "Upper")

table2 <- as.data.frame(rbind(ci.unadjusted, ci.adj, ci.iptw, ci.PScov, ci.match, CIboot.rd, CIboot.rd2))
table2$method <- c("Crude risk difference", "Covariate adjusted", "IPTW", "PS covariate", "Matching", "Simple DR g-computation", "DR using quintiles")
knitr::kable(table2)
```


```{r}
theme_set(theme_bw())
p2 <- ggplot(table2,aes(Estimate,method)) + 
  geom_point(size=5, shape=18) +
  geom_errorbarh(aes(xmax = Upper, xmin = Lower), height = 0.15, lwd=1) +
  geom_vline(xintercept = 0, linetype = "longdash") +
  #scale_x_log10()+
  theme(axis.text = element_text(size=14), axis.title = element_text(size = 14))+
  labs(x="Risk difference", y="Method")
p2
```

```{r, include = FALSE}
pdf(file = "Figures/Plot_RD_dataex.pdf")
p2
dev.off()
```

### References

* Friedrich, S and Friede, T (2020). Causal inference methods for small non-randomized studies: Methods and an application in COVID-19.

* Gautret, P., Lagier, J.-C., Parola, P., Meddeb, L., Mailhe, M., Doudier, B., Courjon, J., Giordanengo, V., Vieira, V. E., Dupont, H. T., et al. (2020). Hydroxychloroquine and azithromycin as a treatment of covid-19: results of an open-label non-randomized clinical trial. International journal of antimicrobial agents, page 105949.

